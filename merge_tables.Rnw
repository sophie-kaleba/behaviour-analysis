source("./scripts/libraries.R", chdir=TRUE)

folder_status <- "../results/11-08-22_18-49-42/"

load_all_tables <- function (folder, head = TRUE, folder_pattern="" ,patt="") { 
  result <- NULL
  
  dir <- list.dirs(folder)
  dir <- dir[ str_detect(dir, folder_pattern)]
  
  files <- sort(list.files(dir, pattern=patt, full.names = T))
  
  for (f in files) {
      options(warn=-1) # to ignore the incomplete final line warning
      data <- read.csv(f, sep=" ", strip.white = TRUE, header=head, check.names = FALSE) #check-names so no weird formatting happens
      result <- bind_rows(result, data)
  }
  result$Benchmark <- revalue(result$Benchmark, 
                      c("AsciidoctorConvertSmall"  = "ADConvert",
                      "AsciidoctorLoadFileSmall" = "ADLoadFile",        
                      "BlogRailsRoutesTwoRoutesTwoRequests" = "BlogRails",             
                      "ChunkyDecodePngImagePass" = "ChunkyDec",                      
                      "FannkuchRedux" = "Fannkuch",                                          
                      "ImageDemoConv" = "ImgDemoConv",
                      "ImageDemoSobel" = "ImgDemoSobel",                 
                      "LeeBench" = "Lee",       
                      "SinatraHello" = "Sinatra"))
  return(result)
}

coverage_data <- load_all_tables(folder_status, FALSE, folder_pattern="Coverage/Global") 
colnames(coverage_data) <- c("Benchmark", "Num.LOC", "LOC.Cov", "Num.Fn", "Fn.Cov")
coverage_data$Benchmark <- revalue(coverage_data$Benchmark, 
                      c("AsciidoctorConvertSmall"  = "ADConvert",
                      "AsciidoctorLoadFileSmall" = "ADLoadFile",        
                      "BlogRailsRoutesTwoRoutesTwoRequests" = "BlogRails",             
                      "ChunkyDecodePngImagePass" = "ChunkyDec",                      
                      "FannkuchRedux" = "Fannkuch",                                          
                      "ImageDemoConv" = "ImgDemoConv",
                      "ImageDemoSobel" = "ImgDemoSobel",                 
                      "LeeBench" = "Lee",       
                      "SinatraHello" = "Sinatra"))


data <- load_all_tables(folder_status, folder_pattern = "Methods/General", patt="one") %>% replace(is.na(.), 0)
data <- join(coverage_data, data) %>% select(c("Benchmark", "Times.Splitted"), everything())
names(data) <- sub('(\\D+)(\\d+$)', '\\2_\\1', names(data))

before <- data %>%
  select(1:6, contains("Before"))
names(before) <- sub('(\\d+)_([a-zA-Z]+).(\\D+)_', '\\1_\\3', names(before))
before <- before[ , gtools::mixedsort(names(before))] %>% select(c("Benchmark", "Num.LOC", "LOC.Cov", "Num.Fn", "Fn.Cov", "Times.Splitted"), everything())

tp <- data %>%
  select(1:6, contains("TP"))
names(tp) <- sub('(\\d+)_([a-zA-Z]+).(\\D+)_', '\\1_\\3', names(tp))
tp <- tp[ , gtools::mixedsort(names(tp))] %>% select(c("Benchmark", "Num.LOC", "LOC.Cov", "Num.Fn", "Fn.Cov", "Times.Splitted"), everything())

splitting <- data %>%
  select(1:6, contains("Split"))
names(splitting) <- sub('(\\d+)_([a-zA-Z]+).(\\D+)_', '\\1_\\3', names(splitting))
splitting <- splitting[ , gtools::mixedsort(names(splitting))] %>% select(c("Benchmark", "Num.LOC", "LOC.Cov", "Num.Fn", "Fn.Cov", "Times.Splitted"), everything())

############################################## UTILS ###############################################  
apply_big_numbers <- function(df) {
  df <-   df %>% 
    dplyr::mutate(across(!Benchmark, as.numeric)) %>%
    purrr::map_df(prettyNum ,big.interval = 3,  big.mark = ",")
  return(df)
}

f0 = function(df) {
  idx = ifelse((df == 0), 0L, col(df))
  apply(idx, 1, max)
}

# From there, build Table 1
# LOC, LOC covered, Fn, Fn covered, Max receivers, number of poly calls, number of poly call-sites
sum_poly <- function(df) {
  df <- df %>% mutate(Max.Target = c(0, names(.))[f0(.) + 1])
  df$Max.Target <- sub("[^0-9]+", "", df$Max.Target)
  
  df$Mono.Calls <- rowSums(df[grep('^[1]_\\w+.\\w+s', names(df))])
  df$Mono.Call.Sites <- rowSums(df[grep('^[1]_\\w+.\\w+.S', names(df))])
  
  df$Poly.Calls <- rowSums(df[grep('^[2-8]_\\w+.\\w+s', names(df))])
  df$Poly.Call.Sites <- rowSums(df[grep('^[2-8]_\\w+.\\w+.S', names(df))])
  
  df$Mega.Calls <- rowSums(df[grep('^([9]|[1-9][0-9])_\\w+.\\w+s', names(df))])
  df$Mega.Call.Sites <- rowSums(df[grep('^([9]|[1-9][0-9])_\\w+.\\w+.S', names(df))])
  
  return(df)
}

############################################################################################# 
before <- sum_poly(before)
tp <- sum_poly(tp)
splitting <- sum_poly(splitting)

# Build the general metrics table
table_one <- before %>%
  select(Benchmark, Num.LOC, LOC.Cov, Num.Fn, Fn.Cov, Max.Target, Mono.Call.Sites, Mono.Calls, Poly.Call.Sites, Poly.Calls, Mega.Call.Sites, Mega.Calls) %>%
  apply_big_numbers() #%>%
#mutate("Poly+Mega.Call.Sites" = Poly.Call.Sites + Mega.Call.Sites, "Poly+Mega.Calls" = Mega.Calls + Poly.Calls, across(!Benchmark, as.numeric)) %>%
#select (-Mega.Call.Sites, -Mega.Calls)

# For table 2 and 3, we need to have 3 temporary tables, one before optim, one after tp, one after splitting
table_before_aux <- before %>%
  select(Benchmark, Mono.Calls, Mono.Call.Sites, Poly.Calls, Poly.Call.Sites, Mega.Calls, Mega.Call.Sites, Max.Target) #%>%
#mutate(Poly.Call.Sites = Poly.Call.Sites + Mega.Call.Sites, Poly.Calls = Mega.Calls + Poly.Calls, across(!Benchmark, as.numeric)) %>%
#select (-Mega.Call.Sites, -Mega.Calls)

table_tp_aux <- tp %>%
  select(Benchmark, Mono.Calls, Mono.Call.Sites, Poly.Calls, Poly.Call.Sites, Mega.Calls, Mega.Call.Sites, Max.Target) %>%
  #mutate(Poly.Call.Sites = Poly.Call.Sites + Mega.Call.Sites, Poly.Calls = Mega.Calls + Poly.Calls, across(!Benchmark, as.numeric)) %>%
  #select (-Mega.Call.Sites, -Mega.Calls) %>%
  rename_with( ~ paste0("TP_", .x), .cols = -Benchmark)

table_split_aux <- splitting %>%
  select(Benchmark, Mono.Calls, Mono.Call.Sites, Poly.Calls, Poly.Call.Sites, Mega.Calls, Mega.Call.Sites, Max.Target) %>%
  #mutate(Poly.Call.Sites = Poly.Call.Sites + Mega.Call.Sites, Poly.Calls = Mega.Calls + Poly.Calls, across(!Benchmark, as.numeric)) %>%
  #select (-Mega.Call.Sites, -Mega.Calls) %>%
  rename_with( ~ paste0("SPLIT_", .x), .cols = -c("Benchmark"))  

# from this table, we can extract Table2, for both calls and call-sites
table_two_aftertp <- table_before_aux %>%
  merge(table_tp_aux) %>%
  #  filter(Poly.Call.Sites > 0) %>% don't summarize just yet, summarize when generating the latex table
  mutate(Change.Mono.Sites = round((100 * (TP_Mono.Call.Sites - `Mono.Call.Sites`)/`Mono.Call.Sites`), 1), 
         Change.Mono.Calls = round((100 * (TP_Mono.Calls - `Mono.Calls`)/`Mono.Calls`),1),
         Change.Poly.Sites = round((100 * (TP_Poly.Call.Sites - Poly.Call.Sites)/Poly.Call.Sites), 1), 
         Change.Poly.Calls = round((100 * (TP_Poly.Calls - Poly.Calls)/Poly.Calls), 1),
         Change.Mega.Sites = round((100 * (TP_Mega.Call.Sites - Mega.Call.Sites)/Mega.Call.Sites), 1), 
         Change.Mega.Calls = round((100 * (TP_Mega.Calls - Mega.Calls)/Mega.Calls), 1))  %>%
  apply_big_numbers()

# from this table, we can extract Table3, for both calls and call-sites. Beware, we still need the number of times they have been split
table_three_aftersplit <- table_tp_aux %>%
  merge(table_split_aux) %>%
  #  filter(TP_Poly.Call.Sites > 0) %>% don't summarize just yet, summarize when generating the latex table
  mutate(Change.Mono.Sites = round((100 * (SPLIT_Mono.Call.Sites - `TP_Mono.Call.Sites`)/`TP_Mono.Call.Sites`), 1), 
         Change.Mono.Calls = round((100 * (SPLIT_Mono.Calls - `TP_Mono.Calls`)/`TP_Mono.Calls`),1),
         Change.Poly.Sites = round((100 * (SPLIT_Poly.Call.Sites - TP_Poly.Call.Sites)/TP_Poly.Call.Sites), 1), 
         Change.Poly.Calls = round((100 * (SPLIT_Poly.Calls - TP_Poly.Calls)/TP_Poly.Calls), 1),
         Change.Mega.Sites = round((100 * (SPLIT_Mega.Call.Sites - TP_Mega.Call.Sites)/TP_Mega.Call.Sites), 1), 
         Change.Mega.Calls = round((100 * (SPLIT_Mega.Calls - TP_Mega.Calls)/TP_Mega.Calls), 1)) %>%
  apply_big_numbers()

# This table displays to which extent the optimizations impacted polymorphism, this is new from the article
table_four_max <- table_before_aux %>%
  merge(table_tp_aux) %>%
  merge(table_split_aux) %>%
  select(Benchmark, Max.Target, TP_Max.Target, SPLIT_Max.Target)
#  filter(Max.Target > 1) don't summarize just yet, summarize when generating the latex table

table_split_transitions <- load_all_tables(folder_status, folder_pattern ="Methods/General" , patt="split")

table_four_max %>% mutate(across(!Benchmark, as.numeric)) %>% dplyr::arrange(desc(Max.Target)) %>% htmlTable
table_split_transitions %>% mutate(across(!Benchmark, as.numeric)) %>% dplyr::arrange(desc(Times.Splitted)) %>% htmlTable 

############################################## LATEX FORMATTING ###############################################
table_one_latex <- kableExtra::kable(table_one, booktabs = TRUE, align = "r")

table_two_sites_latex <- kableExtra::kable(table_two_aftertp %>% select(-Max.Target, -TP_Max.Target, -contains("Calls"), -contains("TP")), booktabs = TRUE, align = "r")

table_two_calls_latex <- kableExtra::kable(table_two_aftertp %>% select(-Max.Target, -TP_Max.Target, -contains("Sites"), -contains("TP")), booktabs = TRUE, align = "r")

table_three_sites_latex <- kableExtra::kable(table_three_aftersplit %>% select(-SPLIT_Max.Target, -TP_Max.Target, -contains("Calls"), -contains("SPLIT")), booktabs = TRUE, align = "r")

table_three_calls_latex <- kableExtra::kable(table_three_aftersplit %>% select(-SPLIT_Max.Target, -TP_Max.Target, -contains("Sites"), -contains("SPLIT")), booktabs = TRUE, align = "r")

table_four_latex <- kableExtra::kable(table_four_max, booktabs = TRUE, align = "r")

table_split_transitions_latex <- kableExtra::kable(table_split_transitions, booktabs = TRUE, align = "r")