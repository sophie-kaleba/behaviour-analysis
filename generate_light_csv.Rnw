source("./scripts/libraries.R", chdir=TRUE)

args = commandArgs(trailingOnly=TRUE)
benchmark_name = args[1]
folder_out = file.path(getwd(),args[2],"results")
filename = args[3]

writeLines(paste("[INFO] Generate the csv for",benchmark_name,"located at",filename,". Generate the csv at",folder_out))

folder_out <- "/home/sopi/Documents/Side_projects/behaviour-analysis/results/07-06-22_16-08-09/results"
benchmark_name <- "BlogRailsRoutesTwoRoutesTwoRequests"
filename <- "./results/07-06-22_16-08-09/BlogRailsRoutesTwoRoutesTwoRequests_Jun07-2022_20:50:52/parsed_BlogRailsRoutesTwoRoutesTwoRequests.mylog"
data <- load_data_file(filename)
data <- clean_data_file(data, FALSE) # remove any invalid data (extra logging info ignored by parsing)

############################################## MAIN TABLES ############################################## 
receivers_overview <- add_number_receivers(data, c(Call.Site, "Benchmark")) 

# These 3 tables should be feed as input to build table one and table two
before_all_optim <- receivers_overview %>% select(-Num.Receiver.Observed) %>% rename(Num.Receiver = Num.Receiver.Original) #focus on Num.Receiver.Original
after_tp <- receivers_overview %>% select(-Num.Receiver.Original) %>% rename(Num.Receiver = Num.Receiver.Observed) #focus on Num.Receiver.Observed
after_splitting <- add_number_receivers(data, c(Call.Site.Target, "Benchmark")) %>% select(-Num.Receiver.Original) %>% rename(Num.Receiver = Num.Receiver.Observed) #after tp has been addressed

mutate_per_state <- function(df, type_of_receiver) {
  result <- df %>%
    group_by_at(type_of_receiver) %>%
    dplyr::summarise(Num.Calls = n_distinct(Call.ID), Num.Call.Sites = n_distinct(Source.Section, Symbol))
  return (result)
}

###### SUMMARY TABLE ONE
# Build a summary table, structure as follows:
# vvvvvvvvvvvvvvvvvvvvvvvvvvvv     MONOMOPRHIC                POLYMOPRHIC                 MEGAMOPRHIC
# vvvvvvvvvvvvvvvvvvvvvvvvvvvv #Calls #Call.Sites       #Calls       #Call.Sites       #Calls       #Call.Sites
# Benchmark #Calls #Call.Sites   1        1         2 3 4 5 6 7 8   2 3 4 5 6 7 8      9 10 ...     9 10 ...
# This table should be generated 2 times: 1 before applying any optimisations, 1 after TP, and one after splitting, which means ...
# it should be applied on 3 different tables
# We should ouput a csv containing this table, that will later be read and aggregated with other benchmarks
# The merging should auto fill missing columns with 0s (not NAs)

generate_table_one <- function(df, benchmark_name) {
  table_one <- mutate_per_state(df, "Num.Receiver") 
  table_one <- tidyr::pivot_wider(table_one, 
                                  names_glue = "{Num.Receiver}_{.value}",
                                  names_from = Num.Receiver, 
                                  values_from = c(Num.Calls, Num.Call.Sites)
  ) 
  table_one$Benchmark = benchmark_name
  return(table_one)
}

table_one_before <- generate_table_one(before_all_optim, benchmark_name)
table_one_tp <- generate_table_one(after_tp, benchmark_name)
table_one_splitting <- generate_table_one(after_splitting, benchmark_name)
#table_one <- table_one %>% select(order(colnames(table_one)))

###### SUMMARY TABLE TWO
# Table summarizing the amount of call sites being mono, poly, mega
# In addition to this table, it would be nice to have a table listing the different call-sites of a benchmark, as well as their different receivers throughout runtime?
# Again, 3 different tables
# In essence:
# Benchmark Lexical.Location Symbol Cache.State Receivers 

generate_table_two <- function(df, receiver_to_ditch, receveiver_to_keep, call_site_type, keep_ct = NULL) {
  table_two <- df %>%
    select(-{{receiver_to_ditch}}, -Call.ID, -Builtin.) %>%
    select(Benchmark, Source.Section, Symbol, {{receveiver_to_keep}}, all_of(keep_ct), Num.Receiver) %>%
    add_lookup_status(call_site_type) %>%
    distinct() %>%
    arrange(Source.Section, Symbol, {{receveiver_to_keep}}, Num.Receiver)
  return(table_two)
}

table_two_before <- generate_table_two(before_all_optim, Observed.Receiver, Original.Receiver, Call.Site) %>% filter(Cache.Type != "MONO")
table_two_tp <- generate_table_two(after_tp, Original.Receiver, Observed.Receiver, Call.Site) %>% filter(Cache.Type != "MONO")
table_two_spliting <- generate_table_two(after_splitting, Original.Receiver, Observed.Receiver, Call.Site.Target, "CT.Address") %>% filter(Cache.Type != "MONO")

############################################## SAVE AS CSV ###############################################
write_on_disk <- function(df, name, path = "") {
  write.table(df,paste(path,paste(benchmark_name, name,".csv",sep="-"), sep="/"), col.names = TRUE, row.names = FALSE) 
}

if (!dir.exists(file.path(folder_out,"Status")) & !dir.exists(file.path(folder_out,"PolyDetails"))) {
  dir.create(file.path(folder_out,"Status"), recursive = TRUE)
  dir.create(file.path(folder_out,"PolyDetails"), recursive = TRUE)
}

write_on_disk(table_one_before, "table_one_before", file.path(folder_out,"Status"))
write_on_disk(table_one_tp, "table_one_tp", file.path(folder_out,"Status"))
write_on_disk(table_one_splitting, "table_one_splitting", file.path(folder_out,"Status"))

write_on_disk(table_two_before, "table_two_before", file.path(folder_out,"PolyDetails"))
write_on_disk(table_two_tp, "table_two_tp", file.path(folder_out,"PolyDetails"))
write_on_disk(table_two_spliting, "table_two_spliting", file.path(folder_out,"PolyDetails"))