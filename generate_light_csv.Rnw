source("./scripts/libraries.R", chdir=TRUE)

# args = commandArgs(trailingOnly=TRUE)
# benchmark_name = args[1]
# folder_out = file.path(getwd(),args[2],"results")
# filename = args[3]
# 
# writeLines(paste("[INFO] Reading trace of ",benchmark_name,"located at",filename,". Generate the csv at",folder_out))

#folder_out <- "/home/sopi/Documents/Side_projects/behaviour-analysis/results/07-06-22_16-08-09/results"
#benchmark_name <- "BlogRailsRoutesTwoRoutesTwoRequests"
filename <- "./results/07-06-22_16-08-09/BlogRailsRoutesTwoRoutesTwoRequests_Jun07-2022_20:50:52/parsed_BlogRailsRoutesTwoRoutesTwoRequests.mylog"

col_names <- c("Symbol", "Original.Receiver", "Source.Section", "CT.Address", "Builtin?", "Observed.Receiver")
data <- fread(filename, header = FALSE, sep="\t", col.names = col_names)
benchmark_name <- str_match(filename, "parsed\\_(.*?)\\.mylog")[2]
data$Benchmark <- benchmark_name

data <- data[!(`Builtin?` %like% "PROC|LAMBDA|block")]
data <- data[, na.omit(.SD)][, Call.ID := 1:.N][, lapply(.SD, str_trim)]

data[ , 
      `:=`(Num.Receiver.Observed = n_distinct(Observed.Receiver), 
       Num.Receiver.Original = n_distinct(Original.Receiver)), by=list(Source.Section, Symbol, Benchmark)]

# These 3 tables should be feed as input to build table one and table two
# WIP - we might not need to have 3 different tables (heavy on memory), we could keep one table, and have 
# 3 different columns: Num.Target.Original, Num.Target.Observed, Num.Target.Observed.W.Splitting
# before_all_optim <- copy(data)
# before_all_optim[, Num.Receiver.Observed := NULL]
# setnames(before_all_optim, "Num.Receiver.Original", "Num.Receiver")
# 
# after_tp <- copy(data)
# after_tp[, Num.Receiver.Original := NULL]
# setnames(after_tp, "Num.Receiver.Observed", "Num.Receiver")
# 
# after_splitting <- copy(data)
# after_splitting[, Num.Receiver.Observed := n_distinct(Observed.Receiver), by=list(Source.Section, Symbol, CT.Address, Benchmark)]
# setnames(after_splitting, "Num.Receiver.Observed", "Num.Receiver")

setnames(data,"Num.Receiver.Original", "Before.Num.Targets")
setnames(data,"Num.Receiver.Observed", "TP.Num.Targets")
data[ , "Split.Num.Targets" := n_distinct(Observed.Receiver), by=list(Source.Section, Symbol, CT.Address, Benchmark)]
data[ , "Times.Splitted" := (n_distinct(CT.Address) - 1), by=list(Source.Section, Symbol)]

############################################## SPLITTING ############################################## 

split_table <- copy(data)
split_table[ , "Num.Calls.Target" := n_distinct(Call.ID), by=list(Source.Section, Symbol, Benchmark)]
split_table <- split_table[, .(Call.ID, Symbol, Source.Section, CT.Address, Observed.Receiver, Benchmark, Num.Calls.Target)]

# and export it as a csv file so our java program can analyse it
split_file <-  paste(getwd(),"/",benchmark_name,"_splitting_data.csv", sep="")
out_split_file <- paste(getwd(),"/","out_",benchmark_name,"_splitting_data.csv", sep="")
fwrite(split_table, split_file, row.names = FALSE)
split_table <- NULL

# call the java program to analyze the data, and then fetch back the results
prev_wd <- getwd()
target_dir <- file.path(getwd(), "splitting-transition","out","production","splitting-transition")
setwd(target_dir)
#system2("java", paste(" CallSiteAnalyzer",split_file, out_split_file, sep=" "))

setwd(prev_wd)
row_names <- c("Source.Section", "Symbol", "Start.ID", "End.ID", "Start.State", "End.State", "Start.Cache.Size", "End.Cache.Size", "Union.Size", "Intersect.Size", "Benchmark", "Num.Calls.Target")
transition_data <- fread(out_split_file, header = FALSE, sep=",", col.names=row_names)

transition_data[ , "Transition.Type" := (fcase(
  (Start.State == 'POLYMORPHIC' & End.State == 'POLYMORPHIC' & Intersect.Size == Union.Size), "Same",
  (Start.State == 'MONOMORPHIC' & End.State == 'MONOMORPHIC' & Intersect.Size == Union.Size), "Same",
  (Start.State == 'MEGAMORPHIC' & End.State == 'MEGAMORPHIC' & Intersect.Size == Union.Size), "Same",
  default = "Different")
)]

transition_data <- transition_data[ , .("Num.Transitions" = n_distinct(Source.Section, Symbol)), by=list(Benchmark, Start.State, End.State, Transition.Type)]

transition_data <- transition_data %>% 
    tidyr::unite("Transition", Start.State:End.State, remove = TRUE, sep=" -> ") %>%
    tidyr::unite("Transition", Transition:Transition.Type, remove = TRUE, sep="_") %>%
    tidyr::spread(Benchmark, Num.Transitions)

old_cols <- c("MONOMORPHIC -> MONOMORPHIC_Different",
              "MONOMORPHIC -> MONOMORPHIC_Same",
              "MONOMORPHIC -> POLYMORPHIC_Different",
              "MONOMORPHIC -> MEGAMORPHIC_Different",
              "POLYMORPHIC -> POLYMORPHIC_Different",
              "POLYMORPHIC -> POLYMORPHIC_Same",
              "POLYMORPHIC -> MONOMORPHIC_Different",
              "POLYMORPHIC -> MEGAMORPHIC_Different",
              "MEGAMORPHIC -> MEGAMORPHIC_Different",
              "MEGAMORPHIC -> MEGAMORPHIC_Same",
              "MEGAMORPHIC -> POLYMORPHIC_Different",
              "MEGAMORPHIC -> MONOMORPHIC_Different")

new_cols <- c("MONO->MONO (!=)",
              "MONO->MONO (=)",
              "MONO->POLY",
              "MONO->MEGA",
              "POLY->POLY (!=)",
              "POLY->POLY (=)",
              "POLY->MONO",
              "POLY->MEGA",
              "MEGA->MEGA (!=)",
              "MEGA->MEGA (=)",
              "MEGA->POLY",
              "MEGA->MONO")


transition_data <- transpose(transition_data, keep.names = "Benchmark", make.names = "Transition")
setnames(transition_data, old_cols, new_cols, skip_absent = TRUE)

############################################## MAIN TABLES ############################################## 
###### SUMMARY TABLE ONE
# Build a summary table, structure as follows:
# vvvvvvvvvvvvvvvvvvvvvvvvvvvv     MONOMOPRHIC                POLYMOPRHIC                 MEGAMOPRHIC
# vvvvvvvvvvvvvvvvvvvvvvvvvvvv #Calls #Call.Sites       #Calls       #Call.Sites       #Calls       #Call.Sites
# Benchmark #Calls #Call.Sites   1        1         2 3 4 5 6 7 8   2 3 4 5 6 7 8      9 10 ...     9 10 ...
# This table should be generated 2 times: 1 before applying any optimisations, 1 after TP, and one after splitting, which means ...
# it should be applied on 3 different tables
# We should ouput a csv containing this table, that will later be read and aggregated with other benchmarks
# The merging should auto fill missing columns with 0s (not NAs)


table_one <- data[ , .(Before.Num.Calls = n_distinct(Call.ID), 
                       Before.Num.Call.Sites = n_distinct(Source.Section, Symbol),
                       Benchmark),
                   by = "Before.Num.Targets"][, dcast(.SD, 
                                                      Benchmark ~ Before.Num.Targets,
                                                      value.var = c("Before.Num.Calls", "Before.Num.Call.Sites"))]

table_one <- table_one[data[ , .(TP.Num.Calls = n_distinct(Call.ID), 
                                 TP.Num.Call.Sites = n_distinct(Source.Section, Symbol),
                                 Benchmark),
                             by = "TP.Num.Targets"][, dcast(.SD, 
                                                            Benchmark ~ TP.Num.Targets,
                                                            value.var = c("TP.Num.Calls", "TP.Num.Call.Sites"))]]

table_one <-  table_one[data[ , .(Split.Num.Calls = n_distinct(Call.ID), 
                                  Split.Num.Call.Sites = n_distinct(Source.Section, Symbol), #This is weird - is this correct?
                                  Benchmark),
                              by = "Split.Num.Targets"][, dcast(.SD, 
                                                                Benchmark ~ Split.Num.Targets,
                                                                value.var = c("Split.Num.Calls", "Split.Num.Call.Sites"))]]


transition_data[ , "Times.Splitted" := rowSums(.SD), .SDcols=is.numeric]
table_one <-  table_one[transition_data[, c("Benchmark","Times.Splitted")]]


###### SUMMARY TABLE TWO
# Table summarizing the amount of call sites being mono, poly, mega
# In addition to this table, it would be nice to have a table listing the different call-sites of a benchmark, as well as their different receivers throughout runtime?
# Again, 3 different tables
# In essence:
# Benchmark Lexical.Location Symbol Cache.State Receivers 

generate_table_two <- function(df, receiver_to_ditch, receveiver_to_keep, call_site_type, keep_ct = NULL) {
  table_two <- df %>%
    select(-{{receiver_to_ditch}}, -Call.ID, -Builtin.) %>%
    select(Benchmark, Source.Section, Symbol, {{receveiver_to_keep}}, all_of(keep_ct), Num.Receiver) %>%
    add_lookup_status(call_site_type) %>%
    distinct() %>%
    arrange(Source.Section, Symbol, {{receveiver_to_keep}}, Num.Receiver)
  return(table_two)
}

table_two_before <- generate_table_two(before_all_optim, Observed.Receiver, Original.Receiver, Call.Site) %>% filter(Cache.Type != "MONO")
table_two_tp <- generate_table_two(after_tp, Original.Receiver, Observed.Receiver, Call.Site) %>% filter(Cache.Type != "MONO")
table_two_spliting <- generate_table_two(after_splitting, Original.Receiver, Observed.Receiver, Call.Site.Target, "CT.Address") %>% filter(Cache.Type != "MONO")

############################################## SAVE AS CSV ###############################################
write_on_disk <- function(df, name, path = "") {
  write.table(df,paste(path,paste(benchmark_name, name,".csv",sep="-"), sep="/"), col.names = TRUE, row.names = FALSE) 
}

if (!dir.exists(file.path(folder_out,"Status")) & !dir.exists(file.path(folder_out,"PolyDetails"))) {
  dir.create(file.path(folder_out,"Status"), recursive = TRUE)
  dir.create(file.path(folder_out,"PolyDetails"), recursive = TRUE)
}

write_on_disk(table_one_before, "table_one_before", file.path(folder_out,"Status"))
write_on_disk(table_one_tp, "table_one_tp", file.path(folder_out,"Status"))
write_on_disk(table_one_splitting, "table_one_splitting", file.path(folder_out,"Status"))

write_on_disk(table_two_before, "table_two_before", file.path(folder_out,"PolyDetails"))
write_on_disk(table_two_tp, "table_two_tp", file.path(folder_out,"PolyDetails"))
write_on_disk(table_two_spliting, "table_two_spliting", file.path(folder_out,"PolyDetails"))