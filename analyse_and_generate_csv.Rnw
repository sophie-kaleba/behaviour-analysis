source("./scripts/libraries.R", chdir=TRUE)

args = commandArgs(trailingOnly=TRUE)
benchmark_name = "Bounce" #args[1]
filename = args[2] #"/home/sopi/Documents/Side_projects/ruby-cs-analyser/results/latest/parsed_Bounce.log" #args[2]

folder_out = args[3] #"/home/sopi/Documents/Side_projects/ruby-cs-analyser/results/latest" #args[3]
keep_startup =as.logical(args[4])# FALSE #as.logical(args[4])
keep_blocks = as.logical(args[5])#TRUE #as.logical(args[5])

col_names <- c("Stage", "Symbol", "Original.Receiver", "Source.Section", "CT.ID", "Builtin?", "Observed.Receiver", "CT.Address")
# old from the paper
#col_names <- c("Stage", "Symbol", "Original.Receiver", "Source.Section", "CT.Address", "Builtin?", "Observed.Receiver", "Call.Site.ID")
data <- fread(filename, header = FALSE, sep="\t", col.names = col_names)
benchmark_name <- str_match(filename, "parsed\\_(.*?)\\.log")[2]
data$Benchmark <- benchmark_name

if (!keep_startup) {
  data <- data[!(`Stage` %like% "STARTUP")] #remove startup data
}

if(!keep_blocks) {
  data <- data[!(`Builtin?` %like% "PROC|LAMBDA|block")] #remove block data
} else {
  data <- data[`Builtin?` %like% "PROC|LAMBDA|block"]
  data$Symbol <- "closure"
}

data <- data[, na.omit(.SD)][, Call.ID := 1:.N][, lapply(.SD, str_trim)]
#data <- data[, na.omit(.SD)][, lapply(.SD, str_trim)]
#data$Call.ID <- as.numeric(data$Call.ID)
#data <- data[order(Call.ID)]

gc()

data[ , 
      `:=`(Num.Receiver.Observed = n_distinct(Observed.Receiver), 
           Num.Receiver.Original = n_distinct(Original.Receiver)), by=list(Source.Section, Symbol, Benchmark)]
# olf from the paper
# data[ , 
#       `:=`(Num.Receiver.Observed = n_distinct(Observed.Receiver), 
#        Num.Receiver.Original = n_distinct(Original.Receiver)), by=list(Source.Section, Symbol, Call.Site.ID, Benchmark)]

gc()

setnames(data,"Num.Receiver.Original", "Before.Num.Targets")
setnames(data,"Num.Receiver.Observed", "TP.Num.Targets")
data[ , "Split.Num.Targets" := n_distinct(Observed.Receiver), by=list(Source.Section, Symbol, CT.Address, Benchmark)]
data[ , "Times.Splitted" := (n_distinct(CT.Address) - 1), by=list(Source.Section, Symbol)]
data[ , "Sites.Per.Method" := n_distinct(Source.Section, Symbol, Benchmark), by=list(Observed.Receiver, Symbol)]
data[ , "Split.Sites.Per.Method" := n_distinct(Source.Section, Symbol, CT.Address, Benchmark), by=list(Observed.Receiver, Symbol)]
# old from the paper
# data[ , "Split.Num.Targets" := n_distinct(Observed.Receiver), by=list(Source.Section, Symbol, Call.Site.ID, CT.Address, Benchmark)]
# data[ , "Times.Splitted" := (n_distinct(CT.Address) - 1), by=list(Source.Section, Symbol, Call.Site.ID)]
# data[ , "Sites.Per.Method" := n_distinct(Source.Section, Symbol, Call.Site.ID, Benchmark), by=list(Observed.Receiver, Symbol)]
# data[ , "Split.Sites.Per.Method" := n_distinct(Source.Section, Symbol, Call.Site.ID, CT.Address, Benchmark), by=list(Observed.Receiver, Symbol)]

gc()

############################################## SPLITTING ############################################## 
split_table <- copy(data)

split_table[ , `:=`(Start.Time = first(Call.ID),
                    End.Time = last(Call.ID)), by = list(Benchmark, Source.Section, Symbol, CT.Address) ]

split_table[, c("Builtin?", "TP.Num.Targets", "Before.Num.Targets", "Split.Num.Targets", "Times.Splitted", "Stage", "Original.Receiver", "Call.ID") := NULL]
setcolorder(split_table, c("Benchmark", "Source.Section", "Symbol", "CT.Address", "Start.Time", "End.Time", "Observed.Receiver"))
split_table <- unique(split_table)
setorderv(split_table, c("Benchmark", "Source.Section", "Symbol", "CT.Address", "Start.Time"))
# old from the paper 
# split_table[ , `:=`(Start.Time = first(Call.ID),
#                     End.Time = last(Call.ID)), by = list(Benchmark, Source.Section, Symbol, Call.Site.ID, CT.Address) ]
# split_table[, c("Builtin?", "TP.Num.Targets", "Before.Num.Targets", "Split.Num.Targets", "Times.Splitted", "Stage", "Original.Receiver", "Call.ID") := NULL]
# setcolorder(split_table, c("Benchmark", "Source.Section", "Symbol", "CT.Address", "Start.Time", "End.Time", "Observed.Receiver", "Call.Site.ID"))
# split_table <- unique(split_table)
# setorderv(split_table, c("Benchmark", "Source.Section", "Symbol", "Call.Site.ID", "CT.Address", "Start.Time"))

# and export it as a csv file so our java program can analyse it
split_file <-  file.path(folder_out, paste(benchmark_name,"_splitting_data.csv", sep=""))
out_split_file <- file.path(folder_out, paste("out_",benchmark_name,"_splitting_data.csv", sep=""))      
fwrite(split_table, split_file, row.names = FALSE)
split_table <- NULL

gc()

# call the java program to analyze the data, and then fetch back the results
prev_wd <- getwd()
target_dir <- file.path(getwd(), "splitting-transition","src")
setwd(target_dir)
system2("java", paste(" CallSiteAnalyzer",split_file, out_split_file, sep=" "))

setwd(prev_wd)
row_names <- c("Source.Section", "Symbol", "Start.ID", "End.ID", "Start.State", "End.State", "Start.Cache.Size", "End.Cache.Size", "Union.Size", "Intersect.Size", "Benchmark")

options(warn=0)
transition_data <- fread(out_split_file, header = FALSE, sep=",")
# old from paper
# row_names <- c("Source.Section", "Symbol", "Start.ID", "End.ID", "Start.State", "End.State", "Start.Cache.Size", "End.Cache.Size", "Union.Size", "Intersect.Size", "Benchmark", "Call.Site.ID")
# transition_data <- fread(out_split_file, header = FALSE, sep=",", col.names=row_names)

if (nrow(transition_data) != 0) {
  names(transition_data) <- row_names
  transition_data[ , "Transition.Type" := (fcase(
    (Start.State == 'POLYMORPHIC' & End.State == 'POLYMORPHIC' & Intersect.Size == Union.Size), "Same",
    (Start.State == 'MONOMORPHIC' & End.State == 'MONOMORPHIC' & Intersect.Size == Union.Size), "Same",
    (Start.State == 'MEGAMORPHIC' & End.State == 'MEGAMORPHIC' & Intersect.Size == Union.Size), "Same",
    default = "Different")
  )]
  
  
  detailed_transition_data <- transition_data[Transition.Type == "Different"][ , `:=`(Start.Cache.Size = NULL,
                                                                                      End.Cache.Size = NULL,
                                                                                      Union.Size = NULL,
                                                                                      Intersect.Size = NULL)]
  
  detailed_transition_data_same <- transition_data[Transition.Type == "Same"][ , `:=`(Start.Cache.Size = NULL,
                                                                                      End.Cache.Size = NULL,
                                                                                      Union.Size = NULL,
                                                                                      Intersect.Size = NULL)]
  
  # from there, the data get summarized
  transition_data <- transition_data[ , .("Num.Transitions" = n_distinct(Source.Section, Symbol)), by=list(Benchmark, Start.State, End.State, Transition.Type)]
  #transition_data <- transition_data[ , .("Num.Transitions" = n_distinct(Source.Section, Symbol, Call.Site.ID)), by=list(Benchmark, Start.State, End.State, Transition.Type)]
  
  transition_data <- transition_data %>% 
    tidyr::unite("Transition", Start.State:End.State, remove = TRUE, sep=" -> ") %>%
    tidyr::unite("Transition", Transition:Transition.Type, remove = TRUE, sep="_") %>%
    tidyr::spread(Benchmark, Num.Transitions)
  
  old_cols <- c("MONOMORPHIC -> MONOMORPHIC_Different",
                "MONOMORPHIC -> MONOMORPHIC_Same",
                "MONOMORPHIC -> POLYMORPHIC_Different",
                "MONOMORPHIC -> MEGAMORPHIC_Different",
                "POLYMORPHIC -> POLYMORPHIC_Different",
                "POLYMORPHIC -> POLYMORPHIC_Same",
                "POLYMORPHIC -> MONOMORPHIC_Different",
                "POLYMORPHIC -> MEGAMORPHIC_Different",
                "MEGAMORPHIC -> MEGAMORPHIC_Different",
                "MEGAMORPHIC -> MEGAMORPHIC_Same",
                "MEGAMORPHIC -> POLYMORPHIC_Different",
                "MEGAMORPHIC -> MONOMORPHIC_Different")
  
  new_cols <- c("MONO->MONO (!=)",
                "MONO->MONO (=)",
                "MONO->POLY",
                "MONO->MEGA",
                "POLY->POLY (!=)",
                "POLY->POLY (=)",
                "POLY->MONO",
                "POLY->MEGA",
                "MEGA->MEGA (!=)",
                "MEGA->MEGA (=)",
                "MEGA->POLY",
                "MEGA->MONO")
  
  
  transition_data <- transpose(transition_data, keep.names = "Benchmark", make.names = "Transition")
  setnames(transition_data, old_cols, new_cols, skip_absent = TRUE)
} else {
  transition_data <- data.table(
    "Benchmark" = benchmark_name,
    "MONO->MONO (!=)" = 0, 
    "MONO->MONO (=)" = 0,
    "Times.Splitted" = 0
  )
  
  detailed_transition_data <- data.frame(
    "Source.Section" = "mock",
    "Symbol" = "mock",
    "Start.ID" =0,
    "End.ID" =0,
    "Start.State"= "MONOMORPHIC",
    "End.State" = "MONOMORPHIC",
    "Start.Cache.Size" =0,
    "End.Cache.Size" =0,
    "Union.Size" =0,
    "Intersect.Size" = 0,
    "Benchmark" = benchmark_name,
    "Transition.Type" = "Same")
  
  detailed_transition_data_same <- data.frame(
    "Source.Section" = "mock",
    "Symbol" = "mock",
    "Start.ID" =0,
    "End.ID" =0,
    "Start.State"= "MONOMORPHIC",
    "End.State" = "MONOMORPHIC",
    "Start.Cache.Size" =0,
    "End.Cache.Size" =0,
    "Union.Size" =0,
    "Intersect.Size" = 0,
    "Benchmark" = benchmark_name,
    "Transition.Type" = "Same")
}

############################################## MAIN TABLES ############################################## 
###### SUMMARY TABLE ONE
# Build a summary table, structure as follows:
# vvvvvvvvvvvvvvvvvvvvvvvvvvvv     MONOMOPRHIC                POLYMOPRHIC                 MEGAMOPRHIC
# vvvvvvvvvvvvvvvvvvvvvvvvvvvv #Calls #Call.Sites       #Calls       #Call.Sites       #Calls       #Call.Sites
# Benchmark #Calls #Call.Sites   1        1         2 3 4 5 6 7 8   2 3 4 5 6 7 8      9 10 ...     9 10 ...
# This table should be generated 2 times: 1 before applying any optimisations, 1 after TP, and one after splitting, which means ...
# it should be applied on 3 different tables
# We should ouput a csv containing this table, that will later be read and aggregated with other benchmarks
# The merging should auto fill missing columns with 0s (not NAs)

table_one <- data[ , .("Before.Num.Call.Sites" = n_distinct(Source.Section, Symbol),
                       "Before.Num.Calls" = n_distinct(Call.ID)),
                        by = list(Benchmark, Before.Num.Targets)]
table_one <- dcast(table_one, Benchmark ~ Before.Num.Targets, value.var = c("Before.Num.Calls", "Before.Num.Call.Sites"))

if(!keep_blocks) {
  tp_aux <- data[ , .("TP.Num.Calls" = n_distinct(Call.ID), 
                      "TP.Num.Call.Sites" = n_distinct(Source.Section, Symbol)),
                  by = list(Benchmark, TP.Num.Targets)]
  tp_aux <- dcast(tp_aux,  Benchmark ~ TP.Num.Targets, value.var = c("TP.Num.Calls", "TP.Num.Call.Sites"))
                  
  table_one <- table_one[tp_aux, on = "Benchmark"]
}

split_aux <- data[ , .(Split.Num.Calls = n_distinct(Call.ID), 
                       Split.Num.Call.Sites = n_distinct(Source.Section, Symbol)), #This is weird - is this correct?
                   by = list(Benchmark, Split.Num.Targets)]
split_aux <- dcast(split_aux, Benchmark ~ Split.Num.Targets, value.var = c("Split.Num.Calls", "Split.Num.Call.Sites"))

table_one <-  table_one[split_aux, on = "Benchmark"]

setDT(transition_data)[ , "Times.Splitted" := rowSums(.SD), .SDcols=is.numeric]
table_one <-  table_one[transition_data[, c("Benchmark","Times.Splitted")]]

###### SUMMARY TABLE TWO
# Table summarizing the amount of call sites being mono, poly, mega
# In addition to this table, it would be nice to have a table listing the different call-sites of a benchmark, as well as their different receivers throughout runtime?
# Again, 3 different tables
# In essence:
# Benchmark Lexical.Location Symbol Cache.State Receivers 
table_two_before <- dt_generate_table_two(data, Observed.Receiver, Original.Receiver, Call.Site, Before.Num.Targets) %>% filter(Cache.Type != "MONO")

if(!keep_blocks) {
table_two_tp <- dt_generate_table_two(data, Original.Receiver, Observed.Receiver, Call.Site, TP.Num.Targets) %>% filter(Cache.Type != "MONO")
}

table_two_spliting <- dt_generate_table_two(data, Original.Receiver, Observed.Receiver, Call.Site.Target, Split.Num.Targets, "CT.Address") %>% 
                              filter(Cache.Type != "MONO")

############################################## CALLER POLYMORPHISM ###############################################
table_caller_polymorphism <- data[ , .(Num.Methods = n_distinct(Observed.Receiver, Symbol)), by = list(Benchmark, Sites.Per.Method)][, dcast(.SD, Benchmark ~ Sites.Per.Method,
                                                                                                                           value.var = c("Num.Methods"))]
table_caller_polymorphism_splitting <- data[ , .(Split.Num.Methods = n_distinct(Observed.Receiver, Symbol)), by = list(Benchmark, Split.Sites.Per.Method)][, dcast(.SD, Benchmark ~ Split.Sites.Per.Method,
                                                                                                                                                       value.var = c("Split.Num.Methods"))]


table_caller_polymorphism[ , "Total.Num.Methods" := rowSums(.SD), .SDcols=is.numeric] 
table_caller_polymorphism_splitting[ , "Total.Num.Methods" := rowSums(.SD), .SDcols=is.numeric]
table_caller_polymorphism_splitting[["Benchmark"]] <- paste(benchmark_name,"Split", sep=".")
table_caller_polymorphism <- rbind(table_caller_polymorphism, table_caller_polymorphism_splitting, fill=TRUE)
setcolorder(table_caller_polymorphism, gtools::mixedsort(names(table_caller_polymorphism)))
table_caller_polymorphism <- table_caller_polymorphism %>% select(c("Benchmark", "Total.Num.Methods", everything()))

detailed_table_caller_polymorphism <- data %>% 
  filter(Sites.Per.Method >= 3 & Split.Sites.Per.Method >= 3) %>% 
  select(Benchmark, Source.Section, Observed.Receiver, Symbol,CT.Address, Sites.Per.Method, Split.Sites.Per.Method) %>%
  distinct(Benchmark, Source.Section, Observed.Receiver, Symbol, CT.Address, .keep_all = TRUE)

############################################## DISTRIBUTION ###############################################
sum_bench <- build_summary_df(data$Before.Num.Targets, benchmark_name)

if(!keep_blocks) {
  metrics <- c("Before.Num.Targets", "TP.Num.Targets", "Split.Num.Targets")
  } else {
  metrics <- c("Before.Num.Targets", "Split.Num.Targets")  
  }

distribution_plots_dynamic <- build_distribution_plots(data, metrics)

static_sites <- data %>% distinct(Source.Section, Symbol, .keep_all = TRUE)
distribution_plots_static <- build_distribution_plots(static_sites, metrics)

############################################## SAVE AS CSV ###############################################
if (keep_blocks) {
  folder_out <- file.path(folder_out,"Blocks")
  if (!dir.exists(file.path(folder_out))) {dir.create(folder_out, recursive = TRUE)}
} else {
  folder_out <- file.path(folder_out,"Methods")
  if (!dir.exists(file.path(folder_out))) {dir.create(folder_out, recursive = TRUE)}
}

if (!keep_startup) {
  folder_out <- file.path(folder_out,"NoStartup")
  if (!dir.exists(file.path(folder_out))) {dir.create(folder_out, recursive = TRUE)}
}

if (!dir.exists(file.path(folder_out,"General")) & !dir.exists(file.path(folder_out,"Details")) & !dir.exists(file.path(folder_out,"Distribution"))) {
  dir.create(file.path(folder_out,"General"), recursive = TRUE)
  dir.create(file.path(folder_out,"Details"), recursive = TRUE)
  dir.create(file.path(folder_out,"Distribution"), recursive = TRUE)
}

dt_write_on_disk(table_one, "table_one", file.path(folder_out,"General"))
dt_write_on_disk(sum_bench, "table_distribution", file.path(folder_out,"Distribution"))
dt_write_on_disk(transition_data, "split_transitions", file.path(folder_out,"General"))
dt_write_on_disk(table_caller_polymorphism, "caller_polymorphism", file.path(folder_out,"General"))

dt_write_on_disk(detailed_table_caller_polymorphism, "detailed_table_caller_polymorphism", file.path(folder_out,"Details"))
dt_write_on_disk(detailed_transition_data, "detailed_split_transitions", file.path(folder_out,"Details"))
dt_write_on_disk(detailed_transition_data_same, "detailed_split_transitions_same", file.path(folder_out,"Details"))

dt_write_on_disk(table_two_before, "table_two_before", file.path(folder_out,"Details"))
if (!keep_blocks) {dt_write_on_disk(table_two_tp, "table_two_tp", file.path(folder_out,"Details"))}
dt_write_on_disk(table_two_spliting, "table_two_splitting", file.path(folder_out,"Details"))

plot_names <- c("boxplot_distrib", "violin_plot")
for (i in 1:length(distribution_plots_dynamic)) {
  ggsave(distribution_plots_dynamic[[i]], device="pdf", path=file.path(folder_out, "Distribution"), filename=paste("dynamic",plot_names[[i]],sep="_"), height = 150, width = 400, units="mm")
  ggsave(distribution_plots_static[[i]], device="pdf", path=file.path(folder_out, "Distribution"), filename=paste("static",plot_names[[i]],sep="_"), height = 150, width = 400, units="mm")
}