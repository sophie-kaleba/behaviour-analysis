source("./scripts/libraries.R", chdir=TRUE)

args = commandArgs(trailingOnly=TRUE)
benchmark_name = args[1]
filename = args[2]

folder_out = args[3]
keep_startup = as.logical(args[4])
keep_blocks = as.logical(args[5])

col_names <- c("Stage", "Symbol", "Original.Receiver", "Source.Section", "CT.Address", "Builtin?", "Observed.Receiver", "Call.Site.ID")
data <- fread(filename, header = FALSE, sep="\t", col.names = col_names)
benchmark_name <- str_match(filename, "parsed\\_(.*?)\\.log")[2]
data$Benchmark <- benchmark_name

if (!keep_startup) {
  data <- data[!(`Stage` %like% "STARTUP")] #remove startup data
}

if(!keep_blocks) {
  data <- data[!(`Builtin?` %like% "PROC|LAMBDA|block")] #remove block data
} else {
  data <- data[`Builtin?` %like% "PROC|LAMBDA|block"]
}

data <- data[, na.omit(.SD)][, Call.ID := 1:.N][, lapply(.SD, str_trim)]

gc()

data[ , 
      `:=`(Num.Receiver.Observed = n_distinct(Observed.Receiver), 
       Num.Receiver.Original = n_distinct(Original.Receiver)), by=list(Source.Section, Symbol, Call.Site.ID, Benchmark)]

gc()

setnames(data,"Num.Receiver.Original", "Before.Num.Targets")
setnames(data,"Num.Receiver.Observed", "TP.Num.Targets")
data[ , "Split.Num.Targets" := n_distinct(Observed.Receiver), by=list(Source.Section, Symbol, Call.Site.ID, CT.Address, Benchmark)]
data[ , "Times.Splitted" := (n_distinct(CT.Address) - 1), by=list(Source.Section, Symbol, Call.Site.ID)]

gc()

############################################## SPLITTING ############################################## 
split_table <- copy(data)
#split_table[ , "Num.Calls.Target" := n_distinct(Call.ID), by=list(Source.Section, Symbol, Benchmark)] don't think we actually use it

split_table[ , `:=`(Start.Time = first(Call.ID),
                    End.Time = last(Call.ID)), by = list(Benchmark, Source.Section, Symbol, Call.Site.ID, CT.Address) ]
split_table[, c("Builtin?", "TP.Num.Targets", "Before.Num.Targets", "Split.Num.Targets", "Times.Splitted", "Stage", "Original.Receiver", "Call.ID") := NULL]
setcolorder(split_table, c("Benchmark", "Source.Section", "Symbol", "CT.Address", "Start.Time", "End.Time", "Observed.Receiver", "Call.Site.ID"))
split_table <- unique(split_table)
setorderv(split_table, c("Benchmark", "Source.Section", "Symbol", "Call.Site.ID", "CT.Address", "Start.Time"))

# and export it as a csv file so our java program can analyse it
split_file <-  file.path(folder_out, paste(benchmark_name,"_splitting_data.csv", sep=""))
out_split_file <- file.path(folder_out, paste("out_",benchmark_name,"_splitting_data.csv", sep=""))      
fwrite(split_table, split_file, row.names = FALSE)
split_table <- NULL

gc()

# call the java program to analyze the data, and then fetch back the results
prev_wd <- getwd()
target_dir <- file.path(getwd(), "splitting-transition","src")
setwd(target_dir)
system2("java", paste(" CallSiteAnalyzer",split_file, out_split_file, sep=" "))

setwd(prev_wd)
row_names <- c("Source.Section", "Symbol", "Start.ID", "End.ID", "Start.State", "End.State", "Start.Cache.Size", "End.Cache.Size", "Union.Size", "Intersect.Size", "Benchmark", "Call.Site.ID")
transition_data <- fread(out_split_file, header = FALSE, sep=",", col.names=row_names)

transition_data[ , "Transition.Type" := (fcase(
  (Start.State == 'POLYMORPHIC' & End.State == 'POLYMORPHIC' & Intersect.Size == Union.Size), "Same",
  (Start.State == 'MONOMORPHIC' & End.State == 'MONOMORPHIC' & Intersect.Size == Union.Size), "Same",
  (Start.State == 'MEGAMORPHIC' & End.State == 'MEGAMORPHIC' & Intersect.Size == Union.Size), "Same",
  default = "Different")
)]


detailed_transition_data <- transition_data[Transition.Type == "Different"][ , `:=`(Start.Cache.Size = NULL,
                                                                                    End.Cache.Size = NULL,
                                                                                    Union.Size = NULL,
                                                                                    Intersect.Size = NULL)]

detailed_transition_data_same <- transition_data[Transition.Type == "Same"][ , `:=`(Start.Cache.Size = NULL,
                                                                                    End.Cache.Size = NULL,
                                                                                    Union.Size = NULL,
                                                                                    Intersect.Size = NULL)]

# from there, the data get summarized
transition_data <- transition_data[ , .("Num.Transitions" = n_distinct(Source.Section, Symbol, Call.Site.ID)), by=list(Benchmark, Start.State, End.State, Transition.Type)]

transition_data <- transition_data %>% 
    tidyr::unite("Transition", Start.State:End.State, remove = TRUE, sep=" -> ") %>%
    tidyr::unite("Transition", Transition:Transition.Type, remove = TRUE, sep="_") %>%
    tidyr::spread(Benchmark, Num.Transitions)

old_cols <- c("MONOMORPHIC -> MONOMORPHIC_Different",
              "MONOMORPHIC -> MONOMORPHIC_Same",
              "MONOMORPHIC -> POLYMORPHIC_Different",
              "MONOMORPHIC -> MEGAMORPHIC_Different",
              "POLYMORPHIC -> POLYMORPHIC_Different",
              "POLYMORPHIC -> POLYMORPHIC_Same",
              "POLYMORPHIC -> MONOMORPHIC_Different",
              "POLYMORPHIC -> MEGAMORPHIC_Different",
              "MEGAMORPHIC -> MEGAMORPHIC_Different",
              "MEGAMORPHIC -> MEGAMORPHIC_Same",
              "MEGAMORPHIC -> POLYMORPHIC_Different",
              "MEGAMORPHIC -> MONOMORPHIC_Different")

new_cols <- c("MONO->MONO (!=)",
              "MONO->MONO (=)",
              "MONO->POLY",
              "MONO->MEGA",
              "POLY->POLY (!=)",
              "POLY->POLY (=)",
              "POLY->MONO",
              "POLY->MEGA",
              "MEGA->MEGA (!=)",
              "MEGA->MEGA (=)",
              "MEGA->POLY",
              "MEGA->MONO")


transition_data <- transpose(transition_data, keep.names = "Benchmark", make.names = "Transition")
setnames(transition_data, old_cols, new_cols, skip_absent = TRUE)

############################################## MAIN TABLES ############################################## 
###### SUMMARY TABLE ONE
# Build a summary table, structure as follows:
# vvvvvvvvvvvvvvvvvvvvvvvvvvvv     MONOMOPRHIC                POLYMOPRHIC                 MEGAMOPRHIC
# vvvvvvvvvvvvvvvvvvvvvvvvvvvv #Calls #Call.Sites       #Calls       #Call.Sites       #Calls       #Call.Sites
# Benchmark #Calls #Call.Sites   1        1         2 3 4 5 6 7 8   2 3 4 5 6 7 8      9 10 ...     9 10 ...
# This table should be generated 2 times: 1 before applying any optimisations, 1 after TP, and one after splitting, which means ...
# it should be applied on 3 different tables
# We should ouput a csv containing this table, that will later be read and aggregated with other benchmarks
# The merging should auto fill missing columns with 0s (not NAs)

table_one <- data[ , .("Before.Num.Call.Sites" = n_distinct(Source.Section, Symbol, Call.Site.ID),
                       "Before.Num.Calls" = n_distinct(Call.ID)),
                        by = list(Benchmark, Before.Num.Targets)]
table_one <- dcast(table_one, Benchmark ~ Before.Num.Targets, value.var = c("Before.Num.Calls", "Before.Num.Call.Sites"))

tp_aux <- data[ , .("TP.Num.Calls" = n_distinct(Call.ID), 
                    "TP.Num.Call.Sites" = n_distinct(Source.Section, Symbol, Call.Site.ID)),
                by = list(Benchmark, TP.Num.Targets)]
tp_aux <- dcast(tp_aux,  Benchmark ~ TP.Num.Targets, value.var = c("TP.Num.Calls", "TP.Num.Call.Sites"))
                
table_one <- table_one[tp_aux, on = "Benchmark"]

split_aux <- data[ , .(Split.Num.Calls = n_distinct(Call.ID), 
                       Split.Num.Call.Sites = n_distinct(Source.Section, Symbol, Call.Site.ID)), #This is weird - is this correct?
                   by = list(Benchmark, Split.Num.Targets)]
split_aux <- dcast(split_aux, Benchmark ~ Split.Num.Targets, value.var = c("Split.Num.Calls", "Split.Num.Call.Sites"))

table_one <-  table_one[split_aux, on = "Benchmark"]

transition_data[ , "Times.Splitted" := rowSums(.SD), .SDcols=is.numeric]
table_one <-  table_one[transition_data[, c("Benchmark","Times.Splitted")]]

###### SUMMARY TABLE TWO
# Table summarizing the amount of call sites being mono, poly, mega
# In addition to this table, it would be nice to have a table listing the different call-sites of a benchmark, as well as their different receivers throughout runtime?
# Again, 3 different tables
# In essence:
# Benchmark Lexical.Location Symbol Cache.State Receivers 
table_two_before <- dt_generate_table_two(data, Observed.Receiver, Original.Receiver, Call.Site, Before.Num.Targets) %>% filter(Cache.Type != "MONO")
table_two_tp <- dt_generate_table_two(data, Original.Receiver, Observed.Receiver, Call.Site, TP.Num.Targets) %>% filter(Cache.Type != "MONO")
table_two_spliting <- dt_generate_table_two(data, Original.Receiver, Observed.Receiver, Call.Site.Target, Split.Num.Targets, "CT.Address") %>% filter(Cache.Type != "MONO")

############################################## DISTRIBUTION ###############################################
sum_bench <- build_summary_df(data$Before.Num.Targets, benchmark_name)

distribution_plots_dynamic <- build_distribution_plots(data, c("Before.Num.Targets", "TP.Num.Targets", "Split.Num.Targets"))

static_sites <- data %>% distinct(Source.Section, Symbol, Call.Site.ID, .keep_all = TRUE)
distribution_plots_static <- build_distribution_plots(static_sites, c("Before.Num.Targets", "TP.Num.Targets", "Split.Num.Targets"))

############################################## SAVE AS CSV ###############################################
dt_write_on_disk <- function(dt, name, path = "") {
  fwrite(dt, file.path(path,paste(benchmark_name,"-",name,".csv",sep="")), col.names = TRUE, row.names = FALSE, sep=" ")
}

if (keep_blocks) {
  folder_out <- file.path(folder_out,"Blocks")
  if (!dir.exists(file.path(folder_out))) {dir.create(folder_out, recursive = TRUE)}
} else {
  folder_out <- file.path(folder_out,"Methods")
  if (!dir.exists(file.path(folder_out))) {dir.create(folder_out, recursive = TRUE)}
}

if (!keep_startup) {
  folder_out <- file.path(folder_out,"NoStartup")
  if (!dir.exists(file.path(folder_out))) {dir.create(folder_out, recursive = TRUE)}
}

if (!dir.exists(file.path(folder_out,"General")) & !dir.exists(file.path(folder_out,"Details")) & !dir.exists(file.path(folder_out,"Distribution"))) {
  dir.create(file.path(folder_out,"General"), recursive = TRUE)
  dir.create(file.path(folder_out,"Details"), recursive = TRUE)
  dir.create(file.path(folder_out,"Distribution"), recursive = TRUE)
}

dt_write_on_disk(table_one, "table_one", file.path(folder_out,"General"))
dt_write_on_disk(sum_bench, "table_distribution", file.path(folder_out,"Distribution"))
dt_write_on_disk(transition_data, "split_transitions", file.path(folder_out,"General"))
dt_write_on_disk(detailed_transition_data, "detailed_split_transitions", file.path(folder_out,"Details"))

dt_write_on_disk(table_two_before, "table_two_before", file.path(folder_out,"Details"))
dt_write_on_disk(table_two_tp, "table_two_tp", file.path(folder_out,"Details"))
dt_write_on_disk(table_two_spliting, "table_two_splitting", file.path(folder_out,"Details"))

plot_names <- c("boxplot_distrib", "violin_plot")
for (i in 1:length(distribution_plots_dynamic)) {
  ggsave(distribution_plots_dynamic[[i]], device="pdf", path=file.path(folder_out, "Distribution"), filename=paste("dynamic",plot_names[[i]],sep="_"), height = 150, width = 400, units="mm")
  ggsave(distribution_plots_static[[i]], device="pdf", path=file.path(folder_out, "Distribution"), filename=paste("static",plot_names[[i]],sep="_"), height = 150, width = 400, units="mm")
}